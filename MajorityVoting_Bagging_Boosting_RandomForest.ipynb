""" 11. Implement and compare Simple Majority Voting Classifier, Bagging Classifier,
Boosting, and Random Forest ensemble learning techniques. Evaluate their
performance on a classification dataset. """

import pandas as pd
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
from sklearn.ensemble import VotingClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC

data = load_breast_cancer()
X = pd.DataFrame(data.data, columns=data.feature_names)
y = pd.Series(data.target)

print("Breast Cancer Dataset Overview:")
print("Dataset shape:", X.shape)
print("Target classes:", data.target_names)
print("\nTarget distribution:")
print(y.value_counts())

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print("\nTraining set size:", len(X_train))
print("Test set size:", len(X_test))

voting = VotingClassifier([
    ("DT", DecisionTreeClassifier(max_depth=3, random_state=42)),
    ("LR", LogisticRegression(max_iter=1000, random_state=42)),
    ("KNN", KNeighborsClassifier(5)),
    ("SVM", SVC(probability=True, random_state=42))
])

bagging = BaggingClassifier(
    estimator=DecisionTreeClassifier(random_state=42),
    n_estimators=50,
    random_state=42
)

adaboost = AdaBoostClassifier(
    estimator=DecisionTreeClassifier(max_depth=1, random_state=42),
    n_estimators=50,
    random_state=42
)

gradient = GradientBoostingClassifier(n_estimators=50, random_state=42)
forest = RandomForestClassifier(n_estimators=50, random_state=42)

models = {
    "Voting Classifier": voting,
    "Bagging": bagging,
    "AdaBoost": adaboost,
    "Gradient Boosting": gradient,
    "Random Forest": forest
}

print("\n" + "="*70)
print("ENSEMBLE LEARNING TECHNIQUES COMPARISON")
print("="*70)

for name, model in models.items():
    model.fit(X_train, y_train)
    pred = model.predict(X_test)
    acc = accuracy_score(y_test, pred)
    cv = cross_val_score(model, X_train, y_train, cv=5)
    print(f"\n{name}")
    print(f"Accuracy: {acc:.4f}")
    print(f"CV Score: {cv.mean():.4f} (Â±{cv.std():.4f})")
